{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3004,"databundleVersionId":861823,"sourceType":"competition"}],"dockerImageVersionId":30198,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport torch\nfrom torch import nn, optim\nimport torchvision\nfrom torch.utils.data import DataLoader\nimport torchvision.transforms as transforms\nimport torchvision.models as models\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-27T13:20:03.189863Z","iopub.execute_input":"2022-12-27T13:20:03.190325Z","iopub.status.idle":"2022-12-27T13:20:07.646709Z","shell.execute_reply.started":"2022-12-27T13:20:03.190244Z","shell.execute_reply":"2022-12-27T13:20:07.645703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Descriminator(nn.Module):\n    def __init__(self, in_features):\n        super().__init__()\n        self.disc = nn.Sequential(\n            nn.Linear(in_features, 256),\n            nn.LeakyReLU(0.1),\n            nn.Linear(256, 128),\n            nn.LeakyReLU(0.1),\n            nn.Linear(128, 1),\n            nn.Sigmoid()\n        )\n    def forward(self, x):\n        return self.disc(x)","metadata":{"execution":{"iopub.status.busy":"2022-12-27T13:20:07.652657Z","iopub.execute_input":"2022-12-27T13:20:07.655301Z","iopub.status.idle":"2022-12-27T13:20:07.665811Z","shell.execute_reply.started":"2022-12-27T13:20:07.655259Z","shell.execute_reply":"2022-12-27T13:20:07.664408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Generator(nn.Module):\n    def __init__(self, z_dim, img_dim):\n        super().__init__()\n        self.gen = nn.Sequential(\n            nn.Linear(z_dim, 256),\n            nn.LeakyReLU(0.1),\n            nn.Linear(256, 512),\n            nn.LeakyReLU(0.1),\n            nn.Linear(512, img_dim),\n            nn.Tanh()\n        )\n    def forward(self, x):\n        return self.gen(x)","metadata":{"execution":{"iopub.status.busy":"2022-12-27T13:20:07.670845Z","iopub.execute_input":"2022-12-27T13:20:07.671938Z","iopub.status.idle":"2022-12-27T13:20:07.679414Z","shell.execute_reply.started":"2022-12-27T13:20:07.671884Z","shell.execute_reply":"2022-12-27T13:20:07.678495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DEVICE  = 'cuda' if torch.cuda.is_available() else 'cpu'\nLR      = 3e-4\nZ_DIM   = 64\nIMG_DIM = 28*28*1\nBS      = 64\nEPOCHS  = 100","metadata":{"execution":{"iopub.status.busy":"2022-12-27T13:20:07.681739Z","iopub.execute_input":"2022-12-27T13:20:07.682528Z","iopub.status.idle":"2022-12-27T13:20:07.832652Z","shell.execute_reply.started":"2022-12-27T13:20:07.682487Z","shell.execute_reply":"2022-12-27T13:20:07.831313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ndisc        = Descriminator(IMG_DIM).to(DEVICE)\ngen         = Generator(Z_DIM, IMG_DIM).to(DEVICE) \nfixed_noice = torch.randn((BS, Z_DIM)).to(DEVICE) \ntransforms  = transforms.Compose([transforms.RandomHorizontalFlip(), transforms.ToTensor(),transforms.Normalize((0.5,),(0.5,))])\ndataset     = torchvision.datasets.MNIST(root = 'dataset/', transform = transforms, download = True)\nloader      = DataLoader(dataset, batch_size=BS, shuffle=True)\nopt_disc    = optim.Adam(disc.parameters(), lr=LR)\nopt_gen     = optim.Adam(gen.parameters(), lr=LR)\ncriterion   = nn.BCELoss()","metadata":{"execution":{"iopub.status.busy":"2022-12-27T13:20:07.834074Z","iopub.execute_input":"2022-12-27T13:20:07.834911Z","iopub.status.idle":"2022-12-27T13:20:13.741891Z","shell.execute_reply.started":"2022-12-27T13:20:07.834864Z","shell.execute_reply":"2022-12-27T13:20:13.740887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"real, y = next(iter(loader))\n_, ax = plt.subplots(5,5, figsize=(10,10))\nplt.suptitle('Some real samples', fontsize=19, fontweight='bold')\n\nind = 0 \nfor k in range(5):\n    for kk in range(5):\n        ind += 1\n        ax[k][kk].imshow(real[ind][0])\n        ","metadata":{"execution":{"iopub.status.busy":"2022-12-27T13:20:13.743282Z","iopub.execute_input":"2022-12-27T13:20:13.743872Z","iopub.status.idle":"2022-12-27T13:20:15.764334Z","shell.execute_reply.started":"2022-12-27T13:20:13.743834Z","shell.execute_reply":"2022-12-27T13:20:15.763463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_fn(loader, device):\n    for real,_ in loader:\n        real       = real.view(-1, 784).to(device)\n        batch_size = real.shape[0]\n        ######## train Discriminator: max log(D(real)) + log(1-D(G(z)))\n        noice     = torch.randn(batch_size, Z_DIM).to(device)\n        fake      = gen(noice)\n        disc_real = disc(real).view(-1) #shape [64,1] -> [64] \n        lossD_real= criterion(disc_real, torch.ones_like(disc_real))\n        disc_fake = disc(fake).view(-1)\n        lossD_fake= criterion(disc_fake, torch.zeros_like(disc_fake))\n        lossD     = (lossD_real + lossD_fake)/2\n        disc.zero_grad()\n        lossD.backward(retain_graph=True) # Add retain_graph=True, To save fake in memory \n        opt_disc.step()\n        \n        ######## train Generator: min log(1-D(G(z))) <==> max log(D(G(z)))\n        output = disc(fake).view(-1)\n        lossG  = criterion(output, torch.ones_like(output))\n        gen.zero_grad()\n        lossG.backward()\n        opt_gen.step()\n        ","metadata":{"execution":{"iopub.status.busy":"2022-12-27T13:20:15.765737Z","iopub.execute_input":"2022-12-27T13:20:15.766366Z","iopub.status.idle":"2022-12-27T13:20:15.775085Z","shell.execute_reply.started":"2022-12-27T13:20:15.766322Z","shell.execute_reply":"2022-12-27T13:20:15.774375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define empty lists to store losses\ngen_losses  = []\ndisc_losses = []\nfor epoch in range(EPOCHS):\n    for batch_idx, (real,_) in enumerate(loader):\n        real       = real.view(-1, 784).to(DEVICE)\n        batch_size = real.shape[0]\n        ######## train Discriminator: max log(D(real)) + log(1-D(G(z)))\n        noice     = torch.randn(batch_size, Z_DIM).to(DEVICE)\n        fake      = gen(noice)\n        disc_real = disc(real).view(-1) #shape [64,1] -> [64] \n        lossD_real= criterion(disc_real, torch.ones_like(disc_real))\n        disc_fake = disc(fake).view(-1)\n        lossD_fake= criterion(disc_fake, torch.zeros_like(disc_fake))\n        lossD     = (lossD_real + lossD_fake)/2\n        disc.zero_grad()\n        lossD.backward(retain_graph=True) # Add retain_graph=True, To save fake in memory \n        opt_disc.step()\n        \n        ######## train Generator: min log(1-D(G(z))) <==> max log(D(G(z)))\n        output = disc(fake).view(-1)\n        lossG  = criterion(output, torch.ones_like(output))\n        gen.zero_grad()\n        lossG.backward()\n        opt_gen.step()\n        \n        # Calculate losses and append to lists\n        gen_losses.append(lossG.item())\n        disc_losses.append(lossD.item())\n        \n            \n    print(\n                f\"Epoch [{epoch}/{EPOCHS}] \\\n                      Loss D: {lossD:.4f}, loss G: {lossG:.4f}\"\n    )\n    \n    if epoch %10 == 0:\n        with torch.no_grad():\n            fake = gen(fixed_noice).reshape(-1, 1, 28, 28).cpu()\n        _, ax = plt.subplots(5,5, figsize=(10,10))\n        plt.suptitle('Results of epoch '+str(epoch), fontsize=19, fontweight='bold')\n\n        ind = 0 \n        for k in range(5):\n            for kk in range(5):\n                ind += 1\n                ax[k][kk].imshow(fake[ind][0])","metadata":{"execution":{"iopub.status.busy":"2022-12-27T13:20:15.778206Z","iopub.execute_input":"2022-12-27T13:20:15.778538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot losses\nplt.plot(gen_losses, label='Generator')\nplt.plot(disc_losses, label='Discriminator')\nplt.legend()\nplt.xlabel('Iteration')\nplt.ylabel('Loss')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]}]}